<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM 중소형 모델 성능 추이 (<100B)</title>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@300;400;500;600&family=JetBrains+Mono:wght@400;500&display=swap');
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'IBM Plex Sans', -apple-system, BlinkMacSystemFont, sans-serif;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: 40px 20px;
            min-height: 100vh;
        }
        
        .container {
            max-width: 1600px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.1);
            padding: 40px;
        }
        
        header {
            margin-bottom: 40px;
        }
        
        h1 {
            font-size: 36px;
            font-weight: 600;
            color: #1a1a1a;
            margin-bottom: 12px;
            letter-spacing: -0.5px;
        }
        
        .subtitle {
            font-size: 16px;
            color: #666;
            font-weight: 400;
        }
        
        .badge {
            display: inline-block;
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white;
            padding: 6px 14px;
            border-radius: 20px;
            font-size: 13px;
            font-weight: 600;
            margin-left: 12px;
            letter-spacing: 0.5px;
        }
        
        .info-box {
            background: #f8f9fa;
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 30px;
            border-left: 4px solid #11998e;
        }
        
        .info-box p {
            font-size: 14px;
            color: #555;
            line-height: 1.6;
            margin-bottom: 8px;
        }
        
        .info-box p:last-child {
            margin-bottom: 0;
        }
        
        .legend {
            display: flex;
            flex-wrap: wrap;
            gap: 16px;
            margin-bottom: 30px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 12px;
        }
        
        .legend-item {
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 13px;
            font-weight: 500;
        }
        
        .legend-color {
            width: 20px;
            height: 20px;
            border-radius: 50%;
            border: 2px solid rgba(255,255,255,0.8);
        }
        
        #chart {
            position: relative;
            width: 100%;
            overflow: hidden;
        }
        
        .tooltip {
            position: absolute;
            padding: 12px 16px;
            background: rgba(0, 0, 0, 0.92);
            color: white;
            border-radius: 8px;
            pointer-events: none;
            font-size: 13px;
            line-height: 1.6;
            opacity: 0;
            transition: opacity 0.2s;
            z-index: 1000;
            max-width: 280px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.3);
        }
        
        .tooltip strong {
            display: block;
            margin-bottom: 6px;
            font-size: 14px;
            font-weight: 600;
        }
        
        .tooltip-lab {
            color: #90caf9;
            font-weight: 500;
        }
        
        .axis-label {
            font-size: 14px;
            font-weight: 600;
            fill: #333;
            letter-spacing: 0.5px;
        }
        
        .grid line {
            stroke: #e0e0e0;
            stroke-opacity: 0.5;
            stroke-dasharray: 2,2;
        }
        
        .grid path {
            stroke-width: 0;
        }
        
        .reference-line {
            stroke: #9e9e9e;
            stroke-width: 1.5;
            stroke-dasharray: 5,5;
            opacity: 0.4;
        }
        
        .reference-label {
            font-size: 11px;
            fill: #666;
            font-weight: 500;
            font-family: 'JetBrains Mono', monospace;
        }
        
        .bubble {
            cursor: pointer;
            transition: all 0.3s ease;
            stroke-width: 2;
            stroke: rgba(255,255,255,0.9);
        }
        
        .bubble:hover {
            stroke-width: 3;
            stroke: rgba(0,0,0,0.3);
            filter: brightness(1.1);
        }
        
        .model-label {
            font-size: 10px;
            font-weight: 500;
            fill: #333;
            pointer-events: none;
            font-family: 'IBM Plex Sans', sans-serif;
            text-shadow: 0 0 3px white, 0 0 3px white, 0 0 3px white;
        }
        
        .axis text {
            font-size: 12px;
            fill: #666;
            font-family: 'JetBrains Mono', monospace;
        }
        
        .axis path,
        .axis line {
            stroke: #bbb;
            stroke-width: 1;
        }
        
        @media (max-width: 1024px) {
            .container {
                padding: 24px;
            }
            
            h1 {
                font-size: 28px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>
                LLM 중소형 모델 성능 추이 
                <span class="badge">&lt;100B 파라미터</span>
            </h1>
            <p class="subtitle">2022-2026년 출시된 효율적인 언어모델의 MMLU 벤치마크 성능</p>
        </header>
        
        <div class="info-box">
            <p><strong>총 90개 중소형 모델</strong> - 100B 미만의 파라미터를 가진 효율적인 모델들</p>
            <p><strong>원의 크기</strong> = 모델 파라미터 수 (2B ~ 80B)</p>
            <p><strong>기준선</strong> (점선) = 89.8점 (인간 전문가 수준)</p>
        </div>
        
        <div class="legend" id="legend"></div>
        
        <div id="chart"></div>
        <div class="tooltip" id="tooltip"></div>
    </div>

    <script>
        const labColors = {
            'Anthropic': '#cc785c',
            'Google DeepMind': '#fbbc04',
            'Google': '#fbbc04',
            'Meta AI': '#0668e1',
            'Mistral': '#2dd4bf',
            'OpenAI': '#10a37f',
            'xAI': '#e91e63',
            'DeepSeek-AI': '#ff6b35',
            'Microsoft': '#00a4ef',
            'NVIDIA': '#76b900',
            'Alibaba': '#ff6a00',
            'Tencent': '#4169e1',
            'LG': '#a50034',
            'SKT': '#ea002c',
            'Upstage AI': '#7c3aed',
            'Baidu': '#2932e1',
            'IBM': '#054ada',
            'Allen AI': '#9333ea'
        };

        function formatDate(decimal) {
            const year = Math.floor(decimal);
            const month = Math.round((decimal - year) * 12) + 1;
            const monthNames = ['1월', '2월', '3월', '4월', '5월', '6월', '7월', '8월', '9월', '10월', '11월', '12월'];
            return `${year}년 ${monthNames[month - 1]}`;
        }

        const vizData = [
        {
                "model": "MedGemma 1.5 4B",
                "lab": "Google DeepMind",
                "date": 2026.0,
                "mmlu": 67.2,
                "parameters": 4.0
        },
        {
                "model": "Engram",
                "lab": "DeepSeek-AI",
                "date": 2026.0,
                "mmlu": 60.6,
                "parameters": 39.5
        },
        {
                "model": "mHC 27B",
                "lab": "DeepSeek-AI",
                "date": 2025.9166666666667,
                "mmlu": 63.4,
                "parameters": 27.0
        },
        {
                "model": "WeDLM",
                "lab": "Tencent",
                "date": 2025.9166666666667,
                "mmlu": 75.14,
                "parameters": 8.0
        },
        {
                "model": "Bolmo",
                "lab": "Allen AI",
                "date": 2025.9166666666667,
                "mmlu": 65.1,
                "parameters": 7.0
        },
        {
                "model": "OLMo 3",
                "lab": "Allen AI",
                "date": 2025.8333333333333,
                "mmlu": 85.4,
                "parameters": 32.0
        },
        {
                "model": "TiDAR",
                "lab": "NVIDIA",
                "date": 2025.8333333333333,
                "mmlu": 76.57,
                "parameters": 8.0
        },
        {
                "model": "ERNIE-4.5-VL-28B-A3B-Thinking",
                "lab": "Baidu",
                "date": 2025.8333333333333,
                "mmlu": 78.9,
                "parameters": 28.0
        },
        {
                "model": "Granite-4.0 Small",
                "lab": "IBM",
                "date": 2025.75,
                "mmlu": 78.33,
                "parameters": 32.0
        },
        {
                "model": "Qwen3-Omni",
                "lab": "Alibaba",
                "date": 2025.6666666666667,
                "mmlu": 88.8,
                "parameters": 30.0
        },
        {
                "model": "Qwen3-Next-80B-A3B",
                "lab": "Alibaba",
                "date": 2025.6666666666667,
                "mmlu": 84.72,
                "parameters": 80.0
        },
        {
                "model": "Jet-Nemotron-4B",
                "lab": "NVIDIA",
                "date": 2025.5833333333333,
                "mmlu": 65.2,
                "parameters": 4.0
        },
        {
                "model": "Nemotron Nano 2",
                "lab": "NVIDIA",
                "date": 2025.5833333333333,
                "mmlu": 78.24,
                "parameters": 12.31
        },
        {
                "model": "gpt-oss-20b",
                "lab": "OpenAI",
                "date": 2025.5833333333333,
                "mmlu": 85.3,
                "parameters": 20.0
        },
        {
                "model": "FlexOlmo",
                "lab": "Allen AI",
                "date": 2025.5,
                "mmlu": 60.4,
                "parameters": 37.0
        },
        {
                "model": "EXAONE 4.0",
                "lab": "LG",
                "date": 2025.5,
                "mmlu": 92.3,
                "parameters": 32.0
        },
        {
                "model": "T5Gemma",
                "lab": "Google DeepMind",
                "date": 2025.5,
                "mmlu": 76.7,
                "parameters": 9.0
        },
        {
                "model": "MedGemma 1 27B",
                "lab": "Google DeepMind",
                "date": 2025.5,
                "mmlu": 87.0,
                "parameters": 27.0
        },
        {
                "model": "Hunyuan-A13B",
                "lab": "Tencent",
                "date": 2025.4166666666667,
                "mmlu": 88.17,
                "parameters": 80.0
        },
        {
                "model": "Gemma 3n",
                "lab": "Google DeepMind",
                "date": 2025.3333333333333,
                "mmlu": 62.1,
                "parameters": 4.0
        },
        {
                "model": "ParScale",
                "lab": "Alibaba",
                "date": 2025.3333333333333,
                "mmlu": 35.1,
                "parameters": 4.7
        },
        {
                "model": "Granite-4.0-Tiny-Preview",
                "lab": "IBM",
                "date": 2025.3333333333333,
                "mmlu": 60.4,
                "parameters": 7.0
        },
        {
                "model": "Bamba-9B-v2",
                "lab": "IBM",
                "date": 2025.25,
                "mmlu": 67.92,
                "parameters": 9.0
        },
        {
                "model": "BitNet b1.58 2B4T",
                "lab": "Microsoft",
                "date": 2025.25,
                "mmlu": 53.17,
                "parameters": 2.0
        },
        {
                "model": "Granite 3.3 8B Instruct",
                "lab": "IBM",
                "date": 2025.25,
                "mmlu": 65.54,
                "parameters": 8.0
        },
        {
                "model": "UltraLong-8B",
                "lab": "NVIDIA",
                "date": 2025.25,
                "mmlu": 67.31,
                "parameters": 8.0
        },
        {
                "model": "Nemotron-H-56B-Base",
                "lab": "NVIDIA",
                "date": 2025.25,
                "mmlu": 84.2,
                "parameters": 56.0
        },
        {
                "model": "EXAONE Deep",
                "lab": "LG",
                "date": 2025.1666666666667,
                "mmlu": 83.0,
                "parameters": 32.0
        },
        {
                "model": "Mistral Small 3.1",
                "lab": "Mistral",
                "date": 2025.1666666666667,
                "mmlu": 81.01,
                "parameters": 24.0
        },
        {
                "model": "OLMo 2 32B",
                "lab": "Allen AI",
                "date": 2025.1666666666667,
                "mmlu": 78.0,
                "parameters": 32.0
        },
        {
                "model": "Gemini Robotics-ER",
                "lab": "Google DeepMind",
                "date": 2025.1666666666667,
                "mmlu": 87.0,
                "parameters": 30.0
        },
        {
                "model": "Gemma 3",
                "lab": "Google DeepMind",
                "date": 2025.1666666666667,
                "mmlu": 78.6,
                "parameters": 27.0
        },
        {
                "model": "Granite-3.2-8B-Instruct",
                "lab": "IBM",
                "date": 2025.0833333333333,
                "mmlu": 66.79,
                "parameters": 8.0
        },
        {
                "model": "Phi-4-mini",
                "lab": "Microsoft",
                "date": 2025.0833333333333,
                "mmlu": 67.3,
                "parameters": 3.8
        },
        {
                "model": "Mistral Saba",
                "lab": "Mistral",
                "date": 2025.0833333333333,
                "mmlu": 81.0,
                "parameters": 24.0
        },
        {
                "model": "Mistral Small 3",
                "lab": "Mistral",
                "date": 2025.0,
                "mmlu": 80.73,
                "parameters": 24.0
        },
        {
                "model": "Bamba-9B",
                "lab": "IBM",
                "date": 2024.9166666666667,
                "mmlu": 60.77,
                "parameters": 9.0
        },
        {
                "model": "BLT",
                "lab": "Meta AI",
                "date": 2024.9166666666667,
                "mmlu": 57.4,
                "parameters": 8.0
        },
        {
                "model": "Phi-4",
                "lab": "Microsoft",
                "date": 2024.9166666666667,
                "mmlu": 84.8,
                "parameters": 14.0
        },
        {
                "model": "Gemini 2.0 Flash exp",
                "lab": "Google DeepMind",
                "date": 2024.9166666666667,
                "mmlu": 87.0,
                "parameters": 30.0
        },
        {
                "model": "Llama 3.3",
                "lab": "Meta AI",
                "date": 2024.9166666666667,
                "mmlu": 86.0,
                "parameters": 70.0
        },
        {
                "model": "EXAONE-3.5",
                "lab": "LG",
                "date": 2024.9166666666667,
                "mmlu": 78.3,
                "parameters": 32.0
        },
        {
                "model": "OLMo 2",
                "lab": "Allen AI",
                "date": 2024.8333333333333,
                "mmlu": 68.6,
                "parameters": 13.0
        },
        {
                "model": "T\u00dcLU 3",
                "lab": "Allen AI",
                "date": 2024.8333333333333,
                "mmlu": 83.1,
                "parameters": 70.0
        },
        {
                "model": "Qwen2.5-Coder",
                "lab": "Alibaba",
                "date": 2024.8333333333333,
                "mmlu": 79.1,
                "parameters": 32.5
        },
        {
                "model": "Granite 3.0 8B",
                "lab": "IBM",
                "date": 2024.75,
                "mmlu": 65.54,
                "parameters": 8.0
        },
        {
                "model": "Granite-3.0-3B-A800M-Instruct",
                "lab": "IBM",
                "date": 2024.75,
                "mmlu": 50.16,
                "parameters": 3.0
        },
        {
                "model": "Ministral 8B",
                "lab": "Mistral",
                "date": 2024.75,
                "mmlu": 65.0,
                "parameters": 8.0
        },
        {
                "model": "NLVM 1.0",
                "lab": "NVIDIA",
                "date": 2024.6666666666667,
                "mmlu": 82.0,
                "parameters": 72.0
        },
        {
                "model": "Llama 3.2 3B",
                "lab": "Meta AI",
                "date": 2024.6666666666667,
                "mmlu": 63.4,
                "parameters": 3.21
        },
        {
                "model": "Qwen2.5",
                "lab": "Alibaba",
                "date": 2024.6666666666667,
                "mmlu": 86.1,
                "parameters": 72.0
        },
        {
                "model": "GRIN MoE",
                "lab": "Microsoft",
                "date": 2024.6666666666667,
                "mmlu": 79.4,
                "parameters": 60.0
        },
        {
                "model": "Pixtral-12b-240910",
                "lab": "Mistral",
                "date": 2024.6666666666667,
                "mmlu": 69.2,
                "parameters": 12.0
        },
        {
                "model": "OLMoE-1B-7B",
                "lab": "Allen AI",
                "date": 2024.6666666666667,
                "mmlu": 54.1,
                "parameters": 6.9
        },
        {
                "model": "Gemini 1.5 Flash-8B",
                "lab": "Google DeepMind",
                "date": 2024.5833333333333,
                "mmlu": 68.1,
                "parameters": 8.0
        },
        {
                "model": "phi-3.5-MoE",
                "lab": "Microsoft",
                "date": 2024.5833333333333,
                "mmlu": 78.9,
                "parameters": 60.0
        },
        {
                "model": "phi-3.5-mini",
                "lab": "Microsoft",
                "date": 2024.5833333333333,
                "mmlu": 65.5,
                "parameters": 3.8
        },
        {
                "model": "Minitron-4B",
                "lab": "NVIDIA",
                "date": 2024.5833333333333,
                "mmlu": 58.6,
                "parameters": 4.0
        },
        {
                "model": "Minitron-8B",
                "lab": "NVIDIA",
                "date": 2024.5,
                "mmlu": 63.8,
                "parameters": 4.0
        },
        {
                "model": "GPT-4o mini",
                "lab": "OpenAI",
                "date": 2024.5,
                "mmlu": 82.0,
                "parameters": 8.0
        },
        {
                "model": "NeMo",
                "lab": "Mistral",
                "date": 2024.5,
                "mmlu": 68.0,
                "parameters": 12.0
        },
        {
                "model": "Mathstral",
                "lab": "Mistral",
                "date": 2024.5,
                "mmlu": 63.47,
                "parameters": 7.0
        },
        {
                "model": "Gemma 2",
                "lab": "Google DeepMind",
                "date": 2024.4166666666667,
                "mmlu": 75.2,
                "parameters": 27.0
        },
        {
                "model": "Claude 3.5 Sonnet",
                "lab": "Anthropic",
                "date": 2024.4166666666667,
                "mmlu": 88.7,
                "parameters": 70.0
        },
        {
                "model": "Qwen2",
                "lab": "Alibaba",
                "date": 2024.4166666666667,
                "mmlu": 84.2,
                "parameters": 72.0
        },
        {
                "model": "Qwen2-57B-A14B",
                "lab": "Alibaba",
                "date": 2024.4166666666667,
                "mmlu": 76.5,
                "parameters": 57.0
        },
        {
                "model": "Chameleon",
                "lab": "Meta AI",
                "date": 2024.3333333333333,
                "mmlu": 65.8,
                "parameters": 34.0
        },
        {
                "model": "Gemini 1.5 Flash",
                "lab": "Google DeepMind",
                "date": 2024.3333333333333,
                "mmlu": 78.9,
                "parameters": 8.0
        },
        {
                "model": "Granite Code",
                "lab": "IBM",
                "date": 2024.3333333333333,
                "mmlu": 50.0,
                "parameters": 34.0
        },
        {
                "model": "phi-3-medium",
                "lab": "Microsoft",
                "date": 2024.25,
                "mmlu": 78.2,
                "parameters": 14.0
        },
        {
                "model": "phi-3-mini",
                "lab": "Microsoft",
                "date": 2024.25,
                "mmlu": 68.8,
                "parameters": 3.8
        },
        {
                "model": "Llama 3 70B",
                "lab": "Meta AI",
                "date": 2024.25,
                "mmlu": 82.0,
                "parameters": 70.0
        },
        {
                "model": "gpt-4-turbo-2024-04-09",
                "lab": "OpenAI",
                "date": 2024.25,
                "mmlu": 86.5,
                "parameters": 70.0
        },
        {
                "model": "Qwen1.5-MoE-A2.7B",
                "lab": "Alibaba",
                "date": 2024.1666666666667,
                "mmlu": 62.5,
                "parameters": 14.3
        },
        {
                "model": "Nemotron-4 15B",
                "lab": "NVIDIA",
                "date": 2024.0833333333333,
                "mmlu": 64.2,
                "parameters": 15.0
        },
        {
                "model": "Hawk",
                "lab": "Google DeepMind",
                "date": 2024.0833333333333,
                "mmlu": 35.0,
                "parameters": 7.0
        },
        {
                "model": "Griffin",
                "lab": "Google DeepMind",
                "date": 2024.0833333333333,
                "mmlu": 49.5,
                "parameters": 14.0
        },
        {
                "model": "Mistral Small",
                "lab": "Mistral",
                "date": 2024.0833333333333,
                "mmlu": 72.2,
                "parameters": 7.0
        },
        {
                "model": "Gemma",
                "lab": "Google DeepMind",
                "date": 2024.0833333333333,
                "mmlu": 64.3,
                "parameters": 7.0
        },
        {
                "model": "Qwen-1.5 72B",
                "lab": "Alibaba",
                "date": 2024.0833333333333,
                "mmlu": 77.5,
                "parameters": 72.0
        },
        {
                "model": "mixtral-8x7b-32kseqlen",
                "lab": "Mistral",
                "date": 2023.9166666666667,
                "mmlu": 70.6,
                "parameters": 46.7
        },
        {
                "model": "Nemotron-3 22B",
                "lab": "NVIDIA",
                "date": 2023.8333333333333,
                "mmlu": 54.4,
                "parameters": 22.0
        },
        {
                "model": "GPT-4 Turbo",
                "lab": "OpenAI",
                "date": 2023.8333333333333,
                "mmlu": 86.4,
                "parameters": 70.0
        },
        {
                "model": "Granite",
                "lab": "IBM",
                "date": 2023.6666666666667,
                "mmlu": 57.0,
                "parameters": 13.0
        },
        {
                "model": "Llama 2",
                "lab": "Meta AI",
                "date": 2023.5,
                "mmlu": 68.9,
                "parameters": 70.0
        },
        {
                "model": "LLaMA-65B",
                "lab": "Meta AI",
                "date": 2023.0833333333333,
                "mmlu": 68.9,
                "parameters": 65.0
        },
        {
                "model": "ChatGPT (gpt-3.5-turbo)",
                "lab": "OpenAI",
                "date": 2022.8333333333333,
                "mmlu": 70.0,
                "parameters": 20.0
        },
        {
                "model": "Atlas",
                "lab": "Meta AI",
                "date": 2022.5833333333333,
                "mmlu": 47.9,
                "parameters": 11.0
        },
        {
                "model": "UL2 20B",
                "lab": "Google",
                "date": 2022.3333333333333,
                "mmlu": 39.2,
                "parameters": 20.0
        },
        {
                "model": "A.X 4.0",
                "lab": "SKT",
                "date": 2025.3333333333333,
                "mmlu": 78.3,
                "parameters": 72.0
        }
];

        const margin = {top: 40, right: 120, bottom: 80, left: 80};
        const width = Math.min(1400, window.innerWidth - 100) - margin.left - margin.right;
        const height = Math.min(800, window.innerHeight - 300) - margin.top - margin.bottom;

        const svg = d3.select('#chart')
            .append('svg')
            .attr('width', width + margin.left + margin.right)
            .attr('height', height + margin.top + margin.bottom)
            .append('g')
            .attr('transform', `translate(${margin.left},${margin.top})`);

        const xScale = d3.scaleLinear()
            .domain([2022, 2026.5])
            .range([0, width]);

        const yScale = d3.scaleLinear()
            .domain([30, 100])
            .range([height, 0]);

        // Linear scale for small/medium models
        const sizeScale = d3.scaleSqrt()
            .domain([0, 100])
            .range([5, 40]);

        const xGrid = d3.axisBottom(xScale)
            .tickSize(-height)
            .tickFormat('')
            .tickValues([2022, 2023, 2024, 2025, 2026]);

        const yGrid = d3.axisLeft(yScale)
            .tickSize(-width)
            .tickFormat('')
            .ticks(10);

        svg.append('g')
            .attr('class', 'grid')
            .attr('transform', `translate(0,${height})`)
            .call(xGrid);

        svg.append('g')
            .attr('class', 'grid')
            .call(yGrid);

        svg.append('line')
            .attr('class', 'reference-line')
            .attr('x1', 0)
            .attr('x2', width)
            .attr('y1', yScale(89.8))
            .attr('y2', yScale(89.8));

        svg.append('text')
            .attr('class', 'reference-label')
            .attr('x', width - 10)
            .attr('y', yScale(89.8) - 8)
            .attr('text-anchor', 'end')
            .text('89.8 = 인간 전문가');

        const xAxis = d3.axisBottom(xScale)
            .tickFormat(d => d.toString())
            .tickValues([2022, 2023, 2024, 2025, 2026]);

        const yAxis = d3.axisLeft(yScale)
            .ticks(10);

        svg.append('g')
            .attr('class', 'axis')
            .attr('transform', `translate(0,${height})`)
            .call(xAxis);

        svg.append('g')
            .attr('class', 'axis')
            .call(yAxis);

        svg.append('text')
            .attr('class', 'axis-label')
            .attr('text-anchor', 'middle')
            .attr('x', width / 2)
            .attr('y', height + 50)
            .text('출시 시기');

        svg.append('text')
            .attr('class', 'axis-label')
            .attr('text-anchor', 'middle')
            .attr('transform', 'rotate(-90)')
            .attr('x', -height / 2)
            .attr('y', -50)
            .text('MMLU 점수');

        const tooltip = d3.select('#tooltip');

        const sortedData = [...vizData].sort((a, b) => b.parameters - a.parameters);

        const bubbles = svg.selectAll('.bubble')
            .data(sortedData)
            .enter()
            .append('circle')
            .attr('class', 'bubble')
            .attr('cx', d => xScale(d.date))
            .attr('cy', d => yScale(d.mmlu))
            .attr('r', d => sizeScale(d.parameters))
            .attr('fill', d => labColors[d.lab] || '#999')
            .attr('opacity', 0.75)
            .on('mouseover', function(event, d) {
                d3.select(this)
                    .transition()
                    .duration(200)
                    .attr('opacity', 1)
                    .attr('stroke-width', 3);
                
                tooltip
                    .style('opacity', 1)
                    .html(`
                        <strong>${d.model}</strong>
                        <div class="tooltip-lab">${d.lab}</div>
                        <div>MMLU: ${d.mmlu.toFixed(1)}</div>
                        <div>파라미터: ${d.parameters.toFixed(1)}B</div>
                        <div>출시: ${formatDate(d.date)}</div>
                    `)
                    .style('left', (event.pageX + 15) + 'px')
                    .style('top', (event.pageY - 15) + 'px');
            })
            .on('mouseout', function(event, d) {
                d3.select(this)
                    .transition()
                    .duration(200)
                    .attr('opacity', 0.75)
                    .attr('stroke-width', 2);
                
                tooltip.style('opacity', 0);
            });

        // Label models with high MMLU or large parameters
        const majorModels = vizData.filter(d => 
            d.mmlu > 85 || d.parameters > 60
        );

        svg.selectAll('.model-label')
            .data(majorModels)
            .enter()
            .append('text')
            .attr('class', 'model-label')
            .attr('x', d => xScale(d.date))
            .attr('y', d => yScale(d.mmlu) - sizeScale(d.parameters) - 4)
            .attr('text-anchor', 'middle')
            .text(d => {
                let label = d.model;
                if (label.length > 20) label = label.substring(0, 17) + '...';
                return label;
            });

        const uniqueLabs = [...new Set(vizData.map(d => d.lab))].sort();
        const legend = d3.select('#legend');

        uniqueLabs.forEach(lab => {
            const item = legend.append('div').attr('class', 'legend-item');
            item.append('div')
                .attr('class', 'legend-color')
                .style('background-color', labColors[lab] || '#999');
            item.append('span').text(lab);
        });

        bubbles
            .attr('r', 0)
            .transition()
            .duration(800)
            .delay((d, i) => i * 10)
            .attr('r', d => sizeScale(d.parameters));
    </script>
</body>
</html>
